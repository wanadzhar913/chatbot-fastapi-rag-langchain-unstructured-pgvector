{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "import unstructured_client\n",
    "from unstructured_client.models import operations, shared\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Using the Unstructured API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson: https://youtu.be/gvY4FgMjZUE?si=_8VXysvehyvjUG7L\n",
    "\n",
    "Here we'll be using the `unstructured-client` [library](https://docs.unstructured.io/api-reference/api-services/sdk-python). However, for production/specific use cases, the authors do recommend using the `unstructured-ingest` library instead. We'll take note of this for future exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = unstructured_client.UnstructuredClient(\n",
    "    api_key_auth=os.getenv(\"UNSTRUCTURED_API_KEY\"),\n",
    "    server_url=os.getenv(\"UNSTRUCTURED_API_URL\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: 'split_pdf_cache_tmp_data' does not exist. Using default value '/tmp'.\n",
      "INFO: HTTP Request: GET https://api.unstructuredapp.io/general/docs \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.unstructuredapp.io/general/v0/general \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.unstructuredapp.io/general/v0/general \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.unstructuredapp.io/general/v0/general \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Title', 'element_id': '35611b6c4191eb4f3163beed2e924f73', 'text': 'GPT4All: An Ecosystem of Open Source Compressed Language Models', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'filename': 'gpt4all.pdf'}}\n"
     ]
    }
   ],
   "source": [
    "filename = \"../data/gpt4all.pdf\"\n",
    "\n",
    "req = operations.PartitionRequest(\n",
    "    partition_parameters=shared.PartitionParameters(\n",
    "        files=shared.Files(\n",
    "            content=open(filename, \"rb\"),\n",
    "            file_name=filename,\n",
    "        ),\n",
    "        strategy=shared.Strategy.HI_RES,\n",
    "        languages=['eng'],\n",
    "        split_pdf_page=True,            # If True, splits the PDF file into smaller chunks of pages.\n",
    "        split_pdf_allow_failed=True,    # If True, the partitioning continues even if some pages fail.\n",
    "        split_pdf_concurrency_level=15  # Set the number of concurrent request to the maximum value: 15.\n",
    "    ),\n",
    ")\n",
    "\n",
    "try:\n",
    "    res = client.general.partition(request=req)\n",
    "    element_dicts = [element for element in res.elements]\n",
    "\n",
    "    # Print the processed data's first element only.\n",
    "    print(element_dicts[0])\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': 17,\n",
       " 'NarrativeText': 80,\n",
       " 'Image': 5,\n",
       " 'Table': 1,\n",
       " 'UncategorizedText': 3}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary to store counts of each type\n",
    "category_counts = {}\n",
    "\n",
    "for element in element_dicts:\n",
    "    category = element['type']\n",
    "    if category in category_counts:\n",
    "        category_counts[category] += 1\n",
    "    else:\n",
    "        category_counts[category] = 1\n",
    "\n",
    "# Unique categories will have unique elements\n",
    "unique_categories = set(category_counts.keys())\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Table Extraction from PDF (Non-API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson: https://youtu.be/m_3q3XnLlTI?si=FlQjVgCDfc0mAzXO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../data/llama3technicalreport.pdf\"\n",
    "\n",
    "pdf_elements = partition_pdf(\n",
    "    filename = filename,\n",
    "    extract_images_in_pdf = False,\n",
    "    strategy = \"hi_res\",\n",
    "    hi_res_model_name = \"yolox\",\n",
    "    infer_table_structure = True,\n",
    "    chunking_strategy=\"by_title\", # https://docs.unstructured.io/api-reference/api-services/chunking\n",
    "    max_characters=3000,\n",
    "    combine_text_under_n_chars=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'CompositeElement',\n",
       " 'element_id': 'b88de6484c5b9e42df1a145f60d240b8',\n",
       " 'text': '4\\n\\n2024\\n\\n2\\n\\n0\\n\\n2 v o N 3 2 ] I A . s c [ 3 v 3 8 7 1 2 . 7 0 4 2 :\\n\\nv\\n\\narXiv\\n\\ni\\n\\nX\\n\\nr\\n\\na\\n\\n© Meta\\n\\nThe Llama 3 Herd of Models\\n\\nLlama Team, AI @ Meta1\\n\\n1A detailed contributor list can be found in the appendix of this paper.\\n\\nModern artificial intelligence (AI) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens. This paper presents an extensive empirical evaluation of Llama 3. We find that Llama 3 delivers comparable quality to leading language models such as GPT-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety. The paper also presents the results of experiments in which we integrate image, video, and speech capabilities into Llama 3 via a compositional approach. We observe this approach performs competitively with the state-of-the-art on image, video, and speech recognition tasks. The resulting models are not yet being broadly released as they are still under development.\\n\\nDate: July 23, 2024 Website: https://llama.meta.com/',\n",
       " 'metadata': {'filetype': 'application/pdf',\n",
       "  'languages': ['eng'],\n",
       "  'last_modified': '2024-12-22T19:47:51',\n",
       "  'page_number': 1,\n",
       "  'orig_elements': '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',\n",
       "  'file_directory': '../data',\n",
       "  'filename': 'llama3technicalreport.pdf'}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_elements[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"<class 'unstructured.documents.elements.CompositeElement'>\": 194,\n",
       " \"<class 'unstructured.documents.elements.Table'>\": 1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary to store counts of each type\n",
    "category_counts = {}\n",
    "\n",
    "for element in pdf_elements:\n",
    "    category = str(type(element))\n",
    "    if category in category_counts:\n",
    "        category_counts[category] += 1\n",
    "    else:\n",
    "        category_counts[category] = 1\n",
    "\n",
    "# Unique categories will have unique elements\n",
    "unique_categories = set(category_counts.keys())\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.elements.Table at 0x7f157189f790>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables = [el for el in pdf_elements if el.category == \"Table\"]\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table><tr><td/><td>Contam.</td><td>Performance gain est</td></tr><tr><td/><td/><td>8B</td><td>70B</td><td>405B</td></tr><tr><td>AGIEval</td><td>98</td><td>8.5</td><td>19.9</td><td>16.3</td></tr><tr><td>BIG-Bench Hard</td><td>95</td><td>26.0</td><td>36.0</td><td>41.0</td></tr><tr><td>BoolQ</td><td>96</td><td>4.0</td><td>47</td><td>3.9</td></tr><tr><td>CommonSenseQA</td><td>30</td><td>0.1</td><td>0.8</td><td>0.6</td></tr><tr><td>DROP</td><td/><td/><td/><td/></tr><tr><td>GSM8k</td><td>41</td><td>0.0</td><td>0.1</td><td>1.3</td></tr><tr><td>HellaSwag</td><td>85</td><td>14.8</td><td>14.8</td><td>14.3</td></tr><tr><td>HumanEval</td><td/><td/><td/><td/></tr><tr><td>MATH</td><td>1</td><td>0.0</td><td>-0.1</td><td>-0.2</td></tr><tr><td>MBPP</td><td/><td/><td/><td/></tr><tr><td>MMLU</td><td/><td/><td/><td/></tr><tr><td>MMLU-Pro</td><td/><td/><td/><td/></tr><tr><td>NaturalQuestions</td><td>52</td><td>16</td><td>0.9</td><td>0.8</td></tr><tr><td>OpenBookQA</td><td>21</td><td>3.0</td><td>3.3</td><td>2.6</td></tr><tr><td>PiQA</td><td>55</td><td>85</td><td>(7.9</td><td>8.1</td></tr><tr><td>QuaC</td><td>99</td><td>24</td><td>11.0</td><td>6.4</td></tr><tr><td>RACE</td><td/><td/><td/><td/></tr><tr><td>SiQA</td><td>63</td><td>20</td><td>23</td><td>2.6</td></tr><tr><td>SQuAD</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>Winogrande</td><td>6</td><td>-0.1</td><td>-0.1</td><td>-0.2</td></tr><tr><td>WorldSense</td><td>73</td><td>-3.1</td><td>-0.4</td><td>3.9</td></tr></table>'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_html = tables[0].metadata.text_as_html\n",
    "table_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for element in pdf_elements:\n",
    "    metadata = element.metadata.to_dict()\n",
    "    del metadata[\"languages\"]\n",
    "    metadata[\"source\"] = metadata[\"filename\"]\n",
    "    documents.append(Document(page_content=element.text, metadata=metadata))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'filetype': 'application/pdf', 'last_modified': '2024-12-22T19:47:51', 'page_number': 1, 'orig_elements': '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', 'file_directory': '../data', 'filename': 'llama3technicalreport.pdf', 'source': 'llama3technicalreport.pdf'}, page_content='4\\n\\n2024\\n\\n2\\n\\n0\\n\\n2 v o N 3 2 ] I A . s c [ 3 v 3 8 7 1 2 . 7 0 4 2 :\\n\\nv\\n\\narXiv\\n\\ni\\n\\nX\\n\\nr\\n\\na\\n\\n© Meta\\n\\nThe Llama 3 Herd of Models\\n\\nLlama Team, AI @ Meta1\\n\\n1A detailed contributor list can be found in the appendix of this paper.\\n\\nModern artificial intelligence (AI) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens. This paper presents an extensive empirical evaluation of Llama 3. We find that Llama 3 delivers comparable quality to leading language models such as GPT-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety. The paper also presents the results of experiments in which we integrate image, video, and speech capabilities into Llama 3 via a compositional approach. We observe this approach performs competitively with the state-of-the-art on image, video, and speech recognition tasks. The resulting models are not yet being broadly released as they are still under development.\\n\\nDate: July 23, 2024 Website: https://llama.meta.com/')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
