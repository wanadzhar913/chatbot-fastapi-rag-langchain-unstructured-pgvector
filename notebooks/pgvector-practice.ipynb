{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "import openai\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key set.\n"
     ]
    }
   ],
   "source": [
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if (openai_key == None):\n",
    "    openai_key = getpass('Provide your OpenAI API key: ')\n",
    "\n",
    "if (not openai_key):\n",
    "    raise Exception('No OpenAI API key provided. Please set the OPENAI_API_KEY environment variable or provide it when prompted.')\n",
    "\n",
    "openai.api_key = openai_key\n",
    "\n",
    "print('OpenAI API key set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = os.getenv('POSTGRES_USER')\n",
    "password = os.getenv('POSTGRES_PASSWORD')\n",
    "dbname = os.getenv('POSTGRES_DB')\n",
    "CONNECTION_STRING = f\"postgresql+psycopg2://{user}:{password}@postgres:5432/{dbname}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to PostgreSQL...\n",
      "Successfully connected to PostgreSQL.\n"
     ]
    }
   ],
   "source": [
    "print('Connecting to PostgreSQL...')\n",
    "conn = psycopg2.connect(\"host=localhost port=5433 dbname=vectordb user=admin password=admin\")\n",
    "    \n",
    "cursor = conn.cursor()\n",
    "\n",
    "print('Successfully connected to PostgreSQL.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('langchain_pg_collection',)\n",
      "('langchain_pg_embedding',)\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"\"\"\n",
    "        SELECT table_name FROM information_schema.tables\n",
    "        WHERE table_schema = 'public'\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "for table in cursor.fetchall():\n",
    "    print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€¢ Data. Compared to prior versions of Llama (Touvron et al., 2023a,b), we improved both the quantity and quality of the data we use for pre-training and post-training. These improvements include the development of more careful pre-processing and curation pipelines for pre-training data and the development of more rigorous quality assurance and filtering approaches for post-training data. We pre-train Llama 3 on a corpus of about 15T multilingual tokens, compared to 1.8T tokens for Llama 2.\n"
     ]
    }
   ],
   "source": [
    "cursor.execute('SELECT * FROM langchain_pg_embedding LIMIT 20')\n",
    "result = cursor.fetchall()\n",
    "\n",
    "print(f'{result[13][3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
